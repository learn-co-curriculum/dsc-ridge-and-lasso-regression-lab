{"nbformat_minor": 2, "cells": [{"source": ["# Ridge and Lasso Regression - Lab"], "cell_type": "markdown", "metadata": {}}, {"source": ["## Introduction"], "cell_type": "markdown", "metadata": {}}, {"source": ["In this lab, you'll practice your knowledge of Ridge and Lasso regression!"], "cell_type": "markdown", "metadata": {}}, {"source": ["## Objectives"], "cell_type": "markdown", "metadata": {}}, {"source": ["You will be able to:"], "cell_type": "markdown", "metadata": {}}, {"source": ["- Use Lasso and ridge regression in Python\n", "- Compare Lasso and Ridge with standard regression"], "cell_type": "markdown", "metadata": {}}, {"source": ["## Housing Prices Data"], "cell_type": "markdown", "metadata": {}}, {"source": ["Let's look at yet another house pricing data set."], "cell_type": "markdown", "metadata": {}}, {"execution_count": 1, "cell_type": "code", "source": ["import pandas as pd\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "\n", "df = pd.read_csv('Housing_Prices/train.csv')"], "outputs": [], "metadata": {"collapsed": true}}, {"source": ["Look at df.info"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 2, "cell_type": "code", "source": ["df.info()"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["<class 'pandas.core.frame.DataFrame'>\n", "RangeIndex: 1460 entries, 0 to 1459\n", "Data columns (total 81 columns):\n", "Id               1460 non-null int64\n", "MSSubClass       1460 non-null int64\n", "MSZoning         1460 non-null object\n", "LotFrontage      1201 non-null float64\n", "LotArea          1460 non-null int64\n", "Street           1460 non-null object\n", "Alley            91 non-null object\n", "LotShape         1460 non-null object\n", "LandContour      1460 non-null object\n", "Utilities        1460 non-null object\n", "LotConfig        1460 non-null object\n", "LandSlope        1460 non-null object\n", "Neighborhood     1460 non-null object\n", "Condition1       1460 non-null object\n", "Condition2       1460 non-null object\n", "BldgType         1460 non-null object\n", "HouseStyle       1460 non-null object\n", "OverallQual      1460 non-null int64\n", "OverallCond      1460 non-null int64\n", "YearBuilt        1460 non-null int64\n", "YearRemodAdd     1460 non-null int64\n", "RoofStyle        1460 non-null object\n", "RoofMatl         1460 non-null object\n", "Exterior1st      1460 non-null object\n", "Exterior2nd      1460 non-null object\n", "MasVnrType       1452 non-null object\n", "MasVnrArea       1452 non-null float64\n", "ExterQual        1460 non-null object\n", "ExterCond        1460 non-null object\n", "Foundation       1460 non-null object\n", "BsmtQual         1423 non-null object\n", "BsmtCond         1423 non-null object\n", "BsmtExposure     1422 non-null object\n", "BsmtFinType1     1423 non-null object\n", "BsmtFinSF1       1460 non-null int64\n", "BsmtFinType2     1422 non-null object\n", "BsmtFinSF2       1460 non-null int64\n", "BsmtUnfSF        1460 non-null int64\n", "TotalBsmtSF      1460 non-null int64\n", "Heating          1460 non-null object\n", "HeatingQC        1460 non-null object\n", "CentralAir       1460 non-null object\n", "Electrical       1459 non-null object\n", "1stFlrSF         1460 non-null int64\n", "2ndFlrSF         1460 non-null int64\n", "LowQualFinSF     1460 non-null int64\n", "GrLivArea        1460 non-null int64\n", "BsmtFullBath     1460 non-null int64\n", "BsmtHalfBath     1460 non-null int64\n", "FullBath         1460 non-null int64\n", "HalfBath         1460 non-null int64\n", "BedroomAbvGr     1460 non-null int64\n", "KitchenAbvGr     1460 non-null int64\n", "KitchenQual      1460 non-null object\n", "TotRmsAbvGrd     1460 non-null int64\n", "Functional       1460 non-null object\n", "Fireplaces       1460 non-null int64\n", "FireplaceQu      770 non-null object\n", "GarageType       1379 non-null object\n", "GarageYrBlt      1379 non-null float64\n", "GarageFinish     1379 non-null object\n", "GarageCars       1460 non-null int64\n", "GarageArea       1460 non-null int64\n", "GarageQual       1379 non-null object\n", "GarageCond       1379 non-null object\n", "PavedDrive       1460 non-null object\n", "WoodDeckSF       1460 non-null int64\n", "OpenPorchSF      1460 non-null int64\n", "EnclosedPorch    1460 non-null int64\n", "3SsnPorch        1460 non-null int64\n", "ScreenPorch      1460 non-null int64\n", "PoolArea         1460 non-null int64\n", "PoolQC           7 non-null object\n", "Fence            281 non-null object\n", "MiscFeature      54 non-null object\n", "MiscVal          1460 non-null int64\n", "MoSold           1460 non-null int64\n", "YrSold           1460 non-null int64\n", "SaleType         1460 non-null object\n", "SaleCondition    1460 non-null object\n", "SalePrice        1460 non-null int64\n", "dtypes: float64(3), int64(35), object(43)\n", "memory usage: 924.0+ KB\n"]}], "metadata": {}}, {"source": ["First, make a selection of the data by removing some of the data with `dtype = object`, this way our first model only contains **continuous features**\n", "\n", "Make sure to remove the SalesPrice column from the predictors (which you store in `X`), then replace missing inputs by the median per feature.\n", "\n", "Store the target in `y`."], "cell_type": "markdown", "metadata": {}}, {"execution_count": 3, "cell_type": "code", "source": ["# Load necessary packages\n", "import numpy as np\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.linear_model import LinearRegression\n", "\n", "# remove \"object\"-type features and SalesPrice from `X`\n", "features = [col for col in df.columns if df[col].dtype in [np.float64, np.int64] and col!='SalePrice']\n", "X = df[features]\n", "\n", "# Impute null values\n", "for col in X:\n", "    med = X[col].median()\n", "    X[col].fillna(value = med, inplace = True)\n", "\n", "# Create y\n", "y = df.SalePrice"], "outputs": [], "metadata": {"collapsed": true}}, {"source": ["Look at the information of `X` again"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 4, "cell_type": "code", "source": ["X.info()"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["<class 'pandas.core.frame.DataFrame'>\n", "RangeIndex: 1460 entries, 0 to 1459\n", "Data columns (total 37 columns):\n", "Id               1460 non-null int64\n", "MSSubClass       1460 non-null int64\n", "LotFrontage      1460 non-null float64\n", "LotArea          1460 non-null int64\n", "OverallQual      1460 non-null int64\n", "OverallCond      1460 non-null int64\n", "YearBuilt        1460 non-null int64\n", "YearRemodAdd     1460 non-null int64\n", "MasVnrArea       1460 non-null float64\n", "BsmtFinSF1       1460 non-null int64\n", "BsmtFinSF2       1460 non-null int64\n", "BsmtUnfSF        1460 non-null int64\n", "TotalBsmtSF      1460 non-null int64\n", "1stFlrSF         1460 non-null int64\n", "2ndFlrSF         1460 non-null int64\n", "LowQualFinSF     1460 non-null int64\n", "GrLivArea        1460 non-null int64\n", "BsmtFullBath     1460 non-null int64\n", "BsmtHalfBath     1460 non-null int64\n", "FullBath         1460 non-null int64\n", "HalfBath         1460 non-null int64\n", "BedroomAbvGr     1460 non-null int64\n", "KitchenAbvGr     1460 non-null int64\n", "TotRmsAbvGrd     1460 non-null int64\n", "Fireplaces       1460 non-null int64\n", "GarageYrBlt      1460 non-null float64\n", "GarageCars       1460 non-null int64\n", "GarageArea       1460 non-null int64\n", "WoodDeckSF       1460 non-null int64\n", "OpenPorchSF      1460 non-null int64\n", "EnclosedPorch    1460 non-null int64\n", "3SsnPorch        1460 non-null int64\n", "ScreenPorch      1460 non-null int64\n", "PoolArea         1460 non-null int64\n", "MiscVal          1460 non-null int64\n", "MoSold           1460 non-null int64\n", "YrSold           1460 non-null int64\n", "dtypes: float64(3), int64(34)\n", "memory usage: 422.1 KB\n"]}], "metadata": {}}, {"source": ["## Let's use this data to perform a first naive linear regression model"], "cell_type": "markdown", "metadata": {}}, {"source": ["Compute the R squared and the MSE for both train and test set."], "cell_type": "markdown", "metadata": {}}, {"execution_count": 5, "cell_type": "code", "source": ["from sklearn.metrics import mean_squared_error, mean_squared_log_error\n", "\n", "# Split in train and test\n", "X_train, X_test, y_train, y_test = train_test_split(X,y)\n", "\n", "# Fit the model and print R2 and MSE for train and test\n", "linreg = LinearRegression()\n", "linreg.fit(X_train, y_train)\n", "\n", "print('Training r^2:', linreg.score(X_train, y_train))\n", "print('Testing r^2:', linreg.score(X_test, y_test))\n", "print('Training MSE:', mean_squared_error(y_train, linreg.predict(X_train)))\n", "print('Testing MSE:', mean_squared_error(y_test, linreg.predict(X_test)))"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Training r^2: 0.8030601358929963\n", "Testing r^2: 0.8329865147721602\n", "Training MSE: 1290704943.3020537\n", "Testing MSE: 905366417.2177311\n"]}], "metadata": {}}, {"source": ["## Normalize your data"], "cell_type": "markdown", "metadata": {}}, {"source": ["We haven't normalized our data, let's create a new model that uses `preprocessing.scale` to scale our predictors!"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 6, "cell_type": "code", "source": ["from sklearn import preprocessing\n", "\n", "# scale the data and perform train test split\n", "X_scaled = preprocessing.scale(X)\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X_scaled,y)"], "outputs": [], "metadata": {"collapsed": true}}, {"source": ["Perform the same linear regression on this data and print out R-squared and MSE."], "cell_type": "markdown", "metadata": {}}, {"execution_count": 7, "cell_type": "code", "source": ["linreg_norm = LinearRegression()\n", "linreg_norm.fit(X_train, y_train)\n", "print('Training r^2:', linreg_norm.score(X_train, y_train))\n", "print('Testing r^2:', linreg_norm.score(X_test, y_test))\n", "print('Training MSE:', mean_squared_error(y_train, linreg_norm.predict(X_train)))\n", "print('Testing MSE:', mean_squared_error(y_test, linreg_norm.predict(X_test)))"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Training r^2: 0.8055920275109645\n", "Testing r^2: 0.8361493699191705\n", "Training MSE: 1282264739.3966734\n", "Testing MSE: 891277647.3701895\n"]}], "metadata": {}}, {"source": ["## Include dummy variables"], "cell_type": "markdown", "metadata": {}}, {"source": ["Your model hasn't included dummy variables so far: let's use the \"object\" variables again and create dummies"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 8, "cell_type": "code", "source": ["# Create X_cat which contains only the categorical variables\n", "features_cat = [col for col in df.columns if df[col].dtype in [np.object]]\n", "X_cat = df[features_cat]\n", "\n", "np.shape(X_cat)"], "outputs": [{"execution_count": 8, "output_type": "execute_result", "data": {"text/plain": ["(1460, 43)"]}, "metadata": {}}], "metadata": {}}, {"execution_count": 9, "cell_type": "code", "source": ["# Make dummies\n", "X_cat = pd.get_dummies(X_cat, drop_first=True)\n", "np.shape(X_cat)"], "outputs": [{"execution_count": 9, "output_type": "execute_result", "data": {"text/plain": ["(1460, 209)"]}, "metadata": {}}], "metadata": {}}, {"source": ["Merge `x_cat` together with our scaled `X` so you have one big predictor dataframe."], "cell_type": "markdown", "metadata": {}}, {"execution_count": 10, "cell_type": "code", "source": ["X_all = pd.concat([pd.DataFrame(X_scaled), X_cat], axis = 1)"], "outputs": [], "metadata": {"collapsed": true}}, {"source": ["Perform the same linear regression on this data and print out R-squared and MSE."], "cell_type": "markdown", "metadata": {}}, {"execution_count": 11, "cell_type": "code", "source": ["X_train, X_test, y_train, y_test = train_test_split(X_all, y)\n", "linreg_all = LinearRegression()\n", "linreg_all.fit(X_train, y_train)\n", "print('Training r^2:', linreg_all.score(X_train, y_train))\n", "print('Testing r^2:', linreg_all.score(X_test, y_test))\n", "print('Training MSE:', mean_squared_error(y_train, linreg_all.predict(X_train)))\n", "print('Testing MSE:', mean_squared_error(y_test, linreg_all.predict(X_test)))"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Training r^2: 0.9214293703577425\n", "Testing r^2: -2.2855415643835795e+17\n", "Training MSE: 464036586.48706615\n", "Testing MSE: 1.7161965346335193e+27\n"]}], "metadata": {}}, {"source": ["Notice the severe overfitting above; our training R squared is quite high, but the testing R squared is negative! Our predictions are far off. Similarly, the scale of the Testing MSE is orders of magnitude higher than that of the training."], "cell_type": "markdown", "metadata": {}}, {"source": ["## Perform Ridge and Lasso regression"], "cell_type": "markdown", "metadata": {}}, {"source": ["Use all the data (normalized features and dummy categorical variables) and perform Lasso and Ridge regression for both! Each time, look at R-squared and MSE."], "cell_type": "markdown", "metadata": {}}, {"source": ["## Lasso"], "cell_type": "markdown", "metadata": {}}, {"source": ["With default parameter (alpha = 1)"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 12, "cell_type": "code", "source": ["from sklearn.linear_model import Lasso, Ridge\n", "\n", "lasso = Lasso() \n", "lasso.fit(X_train, y_train)\n", "print('Training r^2:', lasso.score(X_train, y_train))\n", "print('Testing r^2:', lasso.score(X_test, y_test))\n", "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n", "print('Testing MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Training r^2: 0.9349160654636376\n", "Testing r^2: 0.8866420907306873\n", "Training MSE: 384384431.6242838\n", "Testing MSE: 851196294.5367161\n"]}], "metadata": {}}, {"source": ["With a higher regularization parameter (alpha = 10)"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 13, "cell_type": "code", "source": ["from sklearn.linear_model import Lasso, Ridge\n", "\n", "lasso = Lasso(alpha=10) #Lasso is also known as the L1 norm.\n", "lasso.fit(X_train, y_train)\n", "print('Training r^2:', lasso.score(X_train, y_train))\n", "print('Testing r^2:', lasso.score(X_test, y_test))\n", "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n", "print('Testing MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Training r^2: 0.9296834563276463\n", "Testing r^2: 0.894410839600556\n", "Training MSE: 415288117.81010216\n", "Testing MSE: 792861324.4067702\n"]}], "metadata": {}}, {"source": ["## Ridge"], "cell_type": "markdown", "metadata": {}}, {"source": ["With default parameter (alpha = 1)"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 14, "cell_type": "code", "source": ["from sklearn.linear_model import Lasso, Ridge\n", "\n", "ridge = Ridge() #Lasso is also known as the L1 norm.\n", "ridge.fit(X_train, y_train)\n", "print('Training r^2:', ridge.score(X_train, y_train))\n", "print('Testing r^2:', ridge.score(X_test, y_test))\n", "print('Training MSE:', mean_squared_error(y_train, ridge.predict(X_train)))\n", "print('Testing MSE:', mean_squared_error(y_test, ridge.predict(X_test)))"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Training r^2: 0.9111991262476519\n", "Testing r^2: 0.8752405838510864\n", "Training MSE: 524456206.10053486\n", "Testing MSE: 936809380.29851\n"]}], "metadata": {}}, {"source": ["With default parameter (alpha = 10)"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 15, "cell_type": "code", "source": ["from sklearn.linear_model import Lasso, Ridge\n", "\n", "ridge = Ridge(alpha = 10) #Lasso is also known as the L1 norm.\n", "ridge.fit(X_train, y_train)\n", "print('Training r^2:', ridge.score(X_train, y_train))\n", "print('Testing r^2:', ridge.score(X_test, y_test))\n", "print('Training MSE:', mean_squared_error(y_train, ridge.predict(X_train)))\n", "print('Testing MSE:', mean_squared_error(y_test, ridge.predict(X_test)))"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["Training r^2: 0.8939486068765026\n", "Testing r^2: 0.862471549902248\n", "Training MSE: 626337432.71873\n", "Testing MSE: 1032691127.3431072\n"]}], "metadata": {}}, {"source": ["## Look at the metrics, what are your main conclusions?   \n", "\n", "Conclusions here"], "cell_type": "markdown", "metadata": {}}, {"source": ["## Compare number of parameter estimates that are (very close to) 0 for Ridge and Lasso"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 16, "cell_type": "code", "source": ["print(sum(abs(ridge.coef_) < 10**(-10)))"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["4\n"]}], "metadata": {}}, {"execution_count": 17, "cell_type": "code", "source": ["print(sum(abs(lasso.coef_) < 10**(-10)))"], "outputs": [{"output_type": "stream", "name": "stdout", "text": ["39\n"]}], "metadata": {}}, {"source": ["Compare with the total length of the parameter space and draw conclusions!"], "cell_type": "markdown", "metadata": {}}, {"source": ["Lasso was very effective to essentially perform variable selection and remove about 25% of the variables from your model!"], "cell_type": "markdown", "metadata": {}}, {"execution_count": 18, "cell_type": "code", "source": ["len(lasso.coef_)"], "outputs": [{"execution_count": 18, "output_type": "execute_result", "data": {"text/plain": ["246"]}, "metadata": {}}], "metadata": {}}, {"execution_count": 19, "cell_type": "code", "source": ["sum(abs(lasso.coef_) < 10**(-10))/289"], "outputs": [{"execution_count": 19, "output_type": "execute_result", "data": {"text/plain": ["0.13494809688581316"]}, "metadata": {}}], "metadata": {}}, {"source": ["## Summary"], "cell_type": "markdown", "metadata": {}}, {"source": ["Great! You now know how to perform Lasso and Ridge regression."], "cell_type": "markdown", "metadata": {}}], "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "file_extension": ".py", "version": "2.7.14", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}, "nbformat": 4}
{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Ridge and Lasso Regression - Lab"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Introduction"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In this lab, you'll practice your knowledge on Ridge and Lasso regression!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Objectives"]}, {"cell_type": "markdown", "metadata": {}, "source": ["You will be able to:"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- Use Lasso and ridge regression in Python\n", "- Compare Lasso and Ridge with standard regression"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Housing Prices Data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's look at yet another house pricing data set."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "\n", "df = pd.read_csv('Housing_Prices/train.csv')"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["# __SOLUTION__ \n", "import pandas as pd\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "\n", "df = pd.read_csv('Housing_Prices/train.csv')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Look at df.info"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["<class 'pandas.core.frame.DataFrame'>\n", "RangeIndex: 1460 entries, 0 to 1459\n", "Data columns (total 81 columns):\n", "Id               1460 non-null int64\n", "MSSubClass       1460 non-null int64\n", "MSZoning         1460 non-null object\n", "LotFrontage      1201 non-null float64\n", "LotArea          1460 non-null int64\n", "Street           1460 non-null object\n", "Alley            91 non-null object\n", "LotShape         1460 non-null object\n", "LandContour      1460 non-null object\n", "Utilities        1460 non-null object\n", "LotConfig        1460 non-null object\n", "LandSlope        1460 non-null object\n", "Neighborhood     1460 non-null object\n", "Condition1       1460 non-null object\n", "Condition2       1460 non-null object\n", "BldgType         1460 non-null object\n", "HouseStyle       1460 non-null object\n", "OverallQual      1460 non-null int64\n", "OverallCond      1460 non-null int64\n", "YearBuilt        1460 non-null int64\n", "YearRemodAdd     1460 non-null int64\n", "RoofStyle        1460 non-null object\n", "RoofMatl         1460 non-null object\n", "Exterior1st      1460 non-null object\n", "Exterior2nd      1460 non-null object\n", "MasVnrType       1452 non-null object\n", "MasVnrArea       1452 non-null float64\n", "ExterQual        1460 non-null object\n", "ExterCond        1460 non-null object\n", "Foundation       1460 non-null object\n", "BsmtQual         1423 non-null object\n", "BsmtCond         1423 non-null object\n", "BsmtExposure     1422 non-null object\n", "BsmtFinType1     1423 non-null object\n", "BsmtFinSF1       1460 non-null int64\n", "BsmtFinType2     1422 non-null object\n", "BsmtFinSF2       1460 non-null int64\n", "BsmtUnfSF        1460 non-null int64\n", "TotalBsmtSF      1460 non-null int64\n", "Heating          1460 non-null object\n", "HeatingQC        1460 non-null object\n", "CentralAir       1460 non-null object\n", "Electrical       1459 non-null object\n", "1stFlrSF         1460 non-null int64\n", "2ndFlrSF         1460 non-null int64\n", "LowQualFinSF     1460 non-null int64\n", "GrLivArea        1460 non-null int64\n", "BsmtFullBath     1460 non-null int64\n", "BsmtHalfBath     1460 non-null int64\n", "FullBath         1460 non-null int64\n", "HalfBath         1460 non-null int64\n", "BedroomAbvGr     1460 non-null int64\n", "KitchenAbvGr     1460 non-null int64\n", "KitchenQual      1460 non-null object\n", "TotRmsAbvGrd     1460 non-null int64\n", "Functional       1460 non-null object\n", "Fireplaces       1460 non-null int64\n", "FireplaceQu      770 non-null object\n", "GarageType       1379 non-null object\n", "GarageYrBlt      1379 non-null float64\n", "GarageFinish     1379 non-null object\n", "GarageCars       1460 non-null int64\n", "GarageArea       1460 non-null int64\n", "GarageQual       1379 non-null object\n", "GarageCond       1379 non-null object\n", "PavedDrive       1460 non-null object\n", "WoodDeckSF       1460 non-null int64\n", "OpenPorchSF      1460 non-null int64\n", "EnclosedPorch    1460 non-null int64\n", "3SsnPorch        1460 non-null int64\n", "ScreenPorch      1460 non-null int64\n", "PoolArea         1460 non-null int64\n", "PoolQC           7 non-null object\n", "Fence            281 non-null object\n", "MiscFeature      54 non-null object\n", "MiscVal          1460 non-null int64\n", "MoSold           1460 non-null int64\n", "YrSold           1460 non-null int64\n", "SaleType         1460 non-null object\n", "SaleCondition    1460 non-null object\n", "SalePrice        1460 non-null int64\n", "dtypes: float64(3), int64(35), object(43)\n", "memory usage: 924.0+ KB\n"]}], "source": ["# __SOLUTION__ \n", "df.info()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["First, make a selection of the data by removing some of the data with `dtype = object`, this way our first model only contains **continuous features**\n", "\n", "Make sure to remove the SalesPrice column from the predictors (which you store in `X`), then replace missing inputs by the median per feature.\n", "\n", "Store the target in `y`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load necessary packages\n", "\n", "\n", "# remove \"object\"-type features and SalesPrice from `X`\n", "\n", "\n", "# Impute null values\n", "\n", "\n", "# Create y\n"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# __SOLUTION__ \n", "# Load necessary packages\n", "import numpy as np\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.linear_model import LinearRegression\n", "\n", "# remove \"object\"-type features and SalesPrice from `X`\n", "features = [col for col in df.columns if df[col].dtype in [np.float64, np.int64] and col!='SalePrice']\n", "X = df[features]\n", "\n", "# Impute null values\n", "for col in X:\n", "    med = X[col].median()\n", "    X[col].fillna(value = med, inplace = True)\n", "\n", "# Create y\n", "y = df.SalePrice"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Look at the information of `X` again"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["<class 'pandas.core.frame.DataFrame'>\n", "RangeIndex: 1460 entries, 0 to 1459\n", "Data columns (total 37 columns):\n", "Id               1460 non-null int64\n", "MSSubClass       1460 non-null int64\n", "LotFrontage      1460 non-null float64\n", "LotArea          1460 non-null int64\n", "OverallQual      1460 non-null int64\n", "OverallCond      1460 non-null int64\n", "YearBuilt        1460 non-null int64\n", "YearRemodAdd     1460 non-null int64\n", "MasVnrArea       1460 non-null float64\n", "BsmtFinSF1       1460 non-null int64\n", "BsmtFinSF2       1460 non-null int64\n", "BsmtUnfSF        1460 non-null int64\n", "TotalBsmtSF      1460 non-null int64\n", "1stFlrSF         1460 non-null int64\n", "2ndFlrSF         1460 non-null int64\n", "LowQualFinSF     1460 non-null int64\n", "GrLivArea        1460 non-null int64\n", "BsmtFullBath     1460 non-null int64\n", "BsmtHalfBath     1460 non-null int64\n", "FullBath         1460 non-null int64\n", "HalfBath         1460 non-null int64\n", "BedroomAbvGr     1460 non-null int64\n", "KitchenAbvGr     1460 non-null int64\n", "TotRmsAbvGrd     1460 non-null int64\n", "Fireplaces       1460 non-null int64\n", "GarageYrBlt      1460 non-null float64\n", "GarageCars       1460 non-null int64\n", "GarageArea       1460 non-null int64\n", "WoodDeckSF       1460 non-null int64\n", "OpenPorchSF      1460 non-null int64\n", "EnclosedPorch    1460 non-null int64\n", "3SsnPorch        1460 non-null int64\n", "ScreenPorch      1460 non-null int64\n", "PoolArea         1460 non-null int64\n", "MiscVal          1460 non-null int64\n", "MoSold           1460 non-null int64\n", "YrSold           1460 non-null int64\n", "dtypes: float64(3), int64(34)\n", "memory usage: 422.1 KB\n"]}], "source": ["# __SOLUTION__ \n", " X.info()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Let's use this data to perform a first naive linear regression model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compute the R squared and the MSE for both train and test set."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import mean_squared_error, mean_squared_log_error\n", "\n", "# Split in train and test\n", "\n", "# Fit the model and print R2 and MSE for train and test\n"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Training r^2: 0.804114659599992\n", "Testing r^2: 0.8220293726060767\n", "Training MSE: 1187209332.7110069\n", "Testing MSE: 1250121037.6196253\n"]}], "source": ["# __SOLUTION__ \n", "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n", "\n", "# Split in train and test\n", "X_train, X_test, y_train, y_test = train_test_split(X,y)\n", "\n", "# Fit the model and print R2 and MSE for train and test\n", "linreg = LinearRegression()\n", "linreg.fit(X_train, y_train)\n", "\n", "print('Training r^2:', linreg.score(X_train, y_train))\n", "print('Testing r^2:', linreg.score(X_test, y_test))\n", "print('Training MSE:', mean_squared_error(y_train, linreg.predict(X_train)))\n", "print('Testing MSE:', mean_squared_error(y_test, linreg.predict(X_test)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Normalize your data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We haven't normalized our data, let's create a new model that uses `preprocessing.scale` to scale our predictors!"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn import preprocessing\n", "\n", "# Scale the data and perform train test split\n", "\n"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["# __SOLUTION__ \n", "from sklearn import preprocessing\n", "\n", "# scale the data and perform train test split\n", "X_scaled = preprocessing.scale(X)\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X_scaled,y)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Perform the same linear regression on this data and print out R-squared and MSE."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Training r^2: 0.8074980907068123\n", "Testing r^2: 0.8058185208261739\n", "Training MSE: 1150487580.7440414\n", "Testing MSE: 1416852598.1566381\n"]}], "source": ["# __SOLUTION__ \n", "linreg_norm = LinearRegression()\n", "linreg_norm.fit(X_train, y_train)\n", "print('Training r^2:', linreg_norm.score(X_train, y_train))\n", "print('Testing r^2:', linreg_norm.score(X_test, y_test))\n", "print('Training MSE:', mean_squared_error(y_train, linreg_norm.predict(X_train)))\n", "print('Testing MSE:', mean_squared_error(y_test, linreg_norm.predict(X_test)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Include dummy variables"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Your model hasn't included dummy variables so far: let's use the \"object\" variables again and create dummies"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create X_cat which contains only the categorical variables"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Make dummies\n"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"data": {"text/plain": ["(1460, 43)"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["# __SOLUTION__ \n", "# Create X_cat which contains only the categorical variables\n", "features_cat = [col for col in df.columns if df[col].dtype in [np.object]]\n", "X_cat = df[features_cat]\n", "\n", "np.shape(X_cat)"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"data": {"text/plain": ["(1460, 252)"]}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}], "source": ["# __SOLUTION__ \n", "# Make dummies\n", "X_cat = pd.get_dummies(X_cat)\n", "np.shape(X_cat)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Merge `x_cat` together with our scaled `X` so you have one big predictor dataframe."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["# __SOLUTION__ \n", "X_all = pd.concat([pd.DataFrame(X_scaled), X_cat], axis = 1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Perform the same linear regression on this data and print out R-squared and MSE."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Training r^2: 0.944755253171197\n", "Testing r^2: -4.052906884197962e+19\n", "Training MSE: 307167504.32054794\n", "Testing MSE: 3.405455332774927e+29\n"]}], "source": ["# __SOLUTION__ \n", "X_train, X_test, y_train, y_test = train_test_split(X_all, y)\n", "linreg_all = LinearRegression()\n", "linreg_all.fit(X_train, y_train)\n", "print('Training r^2:', linreg_all.score(X_train, y_train))\n", "print('Testing r^2:', linreg_all.score(X_test, y_test))\n", "print('Training MSE:', mean_squared_error(y_train, linreg_all.predict(X_train)))\n", "print('Testing MSE:', mean_squared_error(y_test, linreg_all.predict(X_test)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Notice the severe overfitting above; our training R squared is quite high, but the testing R squared is negative! Our predictions are far off. Similarly, the scale of the Testing MSE is orders of magnitude higher than that of the training."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Perform Ridge and Lasso regression"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Use all the data (normalized features and dummy categorical variables) and perform Lasso and Ridge regression for both! Each time, look at R-squared and MSE."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Lasso"]}, {"cell_type": "markdown", "metadata": {}, "source": ["With default parameter (alpha = 1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Training r^2: 0.9451071623243285\n", "Testing r^2: 0.8178180225894447\n", "Training MSE: 305210846.6739859\n", "Testing MSE: 1530784210.5309837\n"]}], "source": ["# __SOLUTION__ \n", "from sklearn.linear_model import Lasso, Ridge\n", "\n", "lasso = Lasso() \n", "lasso.fit(X_train, y_train)\n", "print('Training r^2:', lasso.score(X_train, y_train))\n", "print('Testing r^2:', lasso.score(X_test, y_test))\n", "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n", "print('Testing MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["With a higher regularization parameter (alpha = 10)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Training r^2: 0.9438669691644985\n", "Testing r^2: 0.8296396546959763\n", "Training MSE: 312106471.31972647\n", "Testing MSE: 1431452937.3249426\n"]}], "source": ["# __SOLUTION__ \n", "from sklearn.linear_model import Lasso, Ridge\n", "\n", "lasso = Lasso(alpha=10) #Lasso is also known as the L1 norm.\n", "lasso.fit(X_train, y_train)\n", "print('Training r^2:', lasso.score(X_train, y_train))\n", "print('Testing r^2:', lasso.score(X_test, y_test))\n", "print('Training MSE:', mean_squared_error(y_train, lasso.predict(X_train)))\n", "print('Testing MSE:', mean_squared_error(y_test, lasso.predict(X_test)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Ridge"]}, {"cell_type": "markdown", "metadata": {}, "source": ["With default parameter (alpha = 1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Training r^2: 0.9307909182663064\n", "Testing r^2: 0.8360653433796003\n", "Training MSE: 384810902.98655874\n", "Testing MSE: 1377461083.0345898\n"]}], "source": ["# __SOLUTION__ \n", "from sklearn.linear_model import Lasso, Ridge\n", "\n", "ridge = Ridge() #Lasso is also known as the L1 norm.\n", "ridge.fit(X_train, y_train)\n", "print('Training r^2:', ridge.score(X_train, y_train))\n", "print('Testing r^2:', ridge.score(X_test, y_test))\n", "print('Training MSE:', mean_squared_error(y_train, ridge.predict(X_train)))\n", "print('Testing MSE:', mean_squared_error(y_test, ridge.predict(X_test)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["With default parameter (alpha = 10)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Training r^2: 0.9103367925088878\n", "Testing r^2: 0.835576679159496\n", "Training MSE: 498538327.2688102\n", "Testing MSE: 1381567084.533856\n"]}], "source": ["# __SOLUTION__ \n", "from sklearn.linear_model import Lasso, Ridge\n", "\n", "ridge = Ridge(alpha = 10) #Lasso is also known as the L1 norm.\n", "ridge.fit(X_train, y_train)\n", "print('Training r^2:', ridge.score(X_train, y_train))\n", "print('Testing r^2:', ridge.score(X_test, y_test))\n", "print('Training MSE:', mean_squared_error(y_train, ridge.predict(X_train)))\n", "print('Testing MSE:', mean_squared_error(y_test, ridge.predict(X_test)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Look at the metrics, what are your main conclusions?   \n", "\n", "Conclusions here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Compare number of parameter estimates that are (very close to) 0 for Ridge and Lasso"]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["11\n"]}], "source": ["# __SOLUTION__ \n", "print(sum(abs(ridge.coef_) < 10**(-10)))"]}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["86\n"]}], "source": ["# __SOLUTION__ \n", "print(sum(abs(lasso.coef_) < 10**(-10)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Compare with the total length of the parameter space and draw conclusions!"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# number of Ridge params almost zero"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# number of Lasso params almost zero"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Lasso was very effective to essentially perform variable selection and remove about 25% of the variables from your model!"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# your code here"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [{"data": {"text/plain": ["289"]}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}], "source": ["# __SOLUTION__ \n", "len(lasso.coef_)"]}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [{"data": {"text/plain": ["0.2975778546712803"]}, "execution_count": 21, "metadata": {}, "output_type": "execute_result"}], "source": ["# __SOLUTION__ \n", "sum(abs(lasso.coef_) < 10**(-10))/289"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Summary"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Great! You now know how to perform Lasso and Ridge regression."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}